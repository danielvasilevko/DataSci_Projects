---
title: "Predicting Life Expectancy Across the Globe"
author: "Daniel Vasilevko"
output:
  pdf_document: default

---
```{r, echo=FALSE}
data <- read.csv("Life-Expectancy-Data-Updated.csv")
library(ggplot2)
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(car))
suppressPackageStartupMessages(library(lmtest))
```
## Introduction
  This analysis seeks to create model that can accurately predict the life expectancy of a country based on data regarding rates of immunization, levels of malnutrition, economic prosperity, mortality rates and other variables associated with quality of life.
  The dataset used was taken from the World Health Organization and contains information from 179 countries across 15 years (2000-2015). 
  
**Country**: The name of country from which data is coming from. 179 Countries

**Region**: The general region of a given country. 9 regions

**Year**: The year the data was collected. 2000-2015.

**Infant_deaths**: The number of infant deaths per 1000 live births.

**Under_five_deaths**: The number of deaths of children under 5 per 1000 live births.

**Adult_mortality**: The number of adults(age 15-59) dying before age 60 per 1000 adults.

**Alcohol_consumption**: The amount of liters of Alcohol consumed per capita (age 15+).

**Hepatitis_B**: Percentage of 1 year olds who received Hepatitis_B-B immunization.

**Measles**: Percentage of 1 year olds who received Measles immunization.

**Polio**: Percentage of 1 year olds  who received Polio immunization.

**Diphtheria**: Percentage of 1 year old who received Diphtheria immunization.

**Incidents_HIV**: Incident of HIV per 1000 people (age 15-49).

**BMI**: Average BMI. BMI is defined as weight(k) / sqrt(height(m)).

**GDP_per_capita**: The GDP per capita in USD (United States Dollars).

**Population_mln**: The population in millions.

**Thinness_ten_nineteen_years**: Percentage of thinness among adolescents (age 10-19). Thinness defined as BMI < -2 standard deviations below the median.

**Thinness_five_nine_years**: Percentage of thinness among children aged 5 or lower. Thinness defined as BMI < -2 standard deviations below the median.

**Schooling**: Average years that people aged 25+ spent in formal education.

**Economy_status_Developed**: Whether a country is considered "developed".

**Economy_status_Developing**: Whether a country is considered "developing".

**Life_expectancy**: Average life expectancy.

## Fitting the Model
  With the dataset introduced, the proccess of selecting variables to put in the model can begin. Looking at these variables logically there are already a few that need to be pruned.
  
  While 'Economy_status_Developed' and 'Economy_status_Developing' offer potential insight into the prosperity of a specific country, the formula used to determine if a country is "developed" or not was not provided, making this variable unreproducible by studies not sourcing data directly from the World Health Organization.
  
  On paper 'Year' may have some level of correlation with 'Life_expectancy' with standards of living generally rising over time.
  
  
```{r, echo = FALSE, fig.width=4, fig.height=3}
average_life_expectancy_per_year <- aggregate(Life_expectancy ~ Year, data = data, FUN = mean)
ggplot(average_life_expectancy_per_year, aes(x = Year, y = Life_expectancy)) +
  geom_bar(stat = "identity",  fill = "steelblue") +
  labs(x = "Years", y = "Life Expectancy", title = "Life Expectancy Over Time") +
  coord_cartesian(ylim = c(40, 72)) +
  theme_classic()
```
 
  However the passage of time does not directly lead to people living longer. 'Years' merely captures a trend of life expectancy tending to rise due to other factors such as better access to healthcare or financial stability. In an MLR we want variables with a causal relationship with the response variable not a reflection of general trend. 'Years' will not be included in the MLR model but will still be used to better categorize the data. 
  
  The variables 'Region' and 'Country' are to 'Year'. Both 'Region' and 'Country' each have some correlation with a life expectancy.

```{r, echo = FALSE,  fig.width=4, fig.height=3}
average_life_expectancy_per_region <- aggregate(Life_expectancy ~ Region, data = data, FUN = mean)
ggplot(average_life_expectancy_per_region, aes(x = Region, y = Life_expectancy)) +
  geom_bar(stat = "identity",  fill = "steelblue") +
  labs(x = "Regions", y = "Life Expectancy", title = "Life Expectancy Across Regions") +
  coord_cartesian(ylim = c(50, 82)) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 25, hjust = 1))
```
 
However it is the conditions within the 'Country' and 'Region' that causes the change in life expectancy rather than the name of a 'Country' or 'Region. Additionally, this model seeks to work based on numerical data regardless of the time the analysis is conducted. Countries are not stagnant so locking the analytical ability of this model behind a preset 179 countries would be designing for obsolescence. 'Country'  will remain as a method of better categorizing data but will not be used in the MLR model and 'Region' will be removed entirely.
  
  In other regards the data is clean, with 0 NA values across the 17 remaining columns and a consistent and easily readable naming scheme for each variable.
  
```{r, echo=FALSE}
data <- data %>% select(-c(Region, Economy_status_Developed, Economy_status_Developing))

na_counts <- colSums(is.na(data))
na_counts_df <- data.frame(Column = names(na_counts), NA_Count = na_counts)

head(na_counts_df)
```
  
  The remaining variables are suited to be used in a MLR model.
  
# Fitting A Multiple Linear Regression Model
The data set has been trimmed down to contain variables that could function well in creating an MLR. From there we will further clean the data by getting rid of any non-significant variables. 
  
```{r, echo= FALSE}
fit <- lm(Life_expectancy ~ Infant_deaths + Under_five_deaths + Adult_mortality + Alcohol_consumption + Hepatitis_B + Measles + BMI + Polio + Diphtheria+Incidents_HIV + GDP_per_capita + Population_mln + Thinness_ten_nineteen_years + Thinness_five_nine_years + Schooling, data = data)

summary(fit)
```
From the P-values shown above we find 6 variables that are not needed in the model. Measles, Polio, Diphtheria, Population_mln, Thinness_ten_nineteen_years, and Thinness_five_nine_years all have a P-value above .05 meaning they do not accurately explain the behavior of 'Life_expectancy'.

```{r, echo= FALSE}
data <- data %>% select(-c(Measles, Polio, Diphtheria,Population_mln,Thinness_ten_nineteen_years,Thinness_five_nine_years))

fit2 <- lm(Life_expectancy ~ Infant_deaths + Under_five_deaths + Adult_mortality + Alcohol_consumption + Hepatitis_B + BMI +Incidents_HIV + GDP_per_capita + Schooling , data = data)
```

To further cut any unnecessary variables from the model it is a good idea to test for multi-collinearity. Although 'Infant_deaths' and 'Under_five_deaths' are both significant, logically both are very likely to have multi-collinearity as they measure mortality range over essentially the same age range. To see the variables with multi-collinearity we will find each variables Variance Inflation Factor (VIF) which essentially shows how  much of the variable's relevance is casused by collinearity in the model. 

```{r, echo= FALSE}
vif_vals <- vif(fit2)
vif_vals
```
The normal cut off for large multicollinearity is a VIF larger than 10, so suffice to say 'Infant_deaths' and 'Under_five_deaths' are definitely above the cutoff. Since 'Infant_deaths' has a higher VIF than 'Under_five_deaths' and has a slightly higher Standard-Error it will be the variable to be removed.

```{r, echo=FALSE}
data <- data %>% select(-c(Infant_deaths))
fit3 <- lm(Life_expectancy ~ Under_five_deaths + Adult_mortality + Alcohol_consumption + Hepatitis_B + BMI +Incidents_HIV + GDP_per_capita + Schooling , data = data)

vif_vals <- vif(fit3)
vif_vals
```
The remaining 2 variables with moderate MC are 'Under_five_deaths' and 'Adult_mortality'. Since the 2 variables only have moderate multicollinearity and the age ranges of the 2 mortality rates do not intersect for now neither variable will be removed. 

# Outliers
The presence of outliers can greatly skew data and can have disproportionate effects of the inferences made by a model.

Using the built in outlier finder in R we can find all outlier in the data set.
```{r, echo= FALSE}
outlierTest(fit3)
fit3 <- lm(Life_expectancy ~ Under_five_deaths + Adult_mortality + Alcohol_consumption + Hepatitis_B + BMI +Incidents_HIV + GDP_per_capita + Schooling , data = data)
```
With an Bonferroni P-value of 8.7498e-08, under the assumtions of our model, the chances of this data point to exist due to random chance is extremely low, thus making it an outlier.

This built in function only finds the most egregious outliers so it is a good idea to manually look for any outliers in the data. A good way to manually find outliers is by looking at 3 different values. Leverage measures how far an observations predictor values are from the mean Standardized Residuals measure how far an observations response values are from the mean. Cooks Distance measures how much influence a given point has on a variable.

```{r, echo = FALSE}
influencePlot(fit3,
              main = "Influence Plot",
              sub = "Circle size is proportional to Cook's Distance")
```

With the influence plot we can clearly see that that obsetvation 1126 exudes a high level of influence on the data while having a high residual value meaning the point should be removed.
```{r, echo = FALSE}

data <- data[-c(1126),]
rownames(data) <- NULL
fit4 <- lm(Life_expectancy ~ Under_five_deaths + Adult_mortality + Alcohol_consumption + Hepatitis_B + BMI +Incidents_HIV + GDP_per_capita + Schooling , data = data)
```

# Assumptions of Multiple Linear Regression

Using a set of plots we can confirm assumptions of Linearity, Normality of Residuals, Homoscedasticity and the model was checked for outliers.


```{r, echo= FALSE}
par(mfrow = c(2, 2))
plot(fit4)
par(mfrow = c(1, 1))
```

**Residuals vs Fitted Plot**: The line is approximately straight and the errors tend to cluster around 0 indicating that the model satisfies the assumption of linearity.

**Normal Q-Q Plot**: The points follow a straight line indicating that residuals are normally distributed meaning the model satisfies the assumption of normality of errors.

**Scale-Location Plot**: The line is approximately straight and has no clear pattern indicating that model satisfies the assumption of homoscedasticity.

**Residuals vs Leverage**: No points with high leverage have a high standardized residual meaning there it is confirmed there are no outliers in the data set.

# Model Selection

With all assumptions of Multiple Linear Assumption confirmed the best model can be selected. To find the best model  Backwards Stepwise Regression can be used which takes away variables from the model to try to create the most optimized model. The test used to compute the quality of the model was Akaike Information Criterion which rewards good fit while penalizing high complexity.

```{r, echo=FALSE}
back_AIC <- step(fit4, direction = "backward", data= data)
print(back_AIC)
```
As shown above, every variable taken from the model resulted in worse performance, meaning the base model was the best. The influence of each variable is then observed with ANOVA.

```{r, echo = FALSE}
Anova(back_AIC)
```
The ANOVA table shows that each predictor has a significant effect on the outcome, as indicated by their small p-values (all less than 0.05). The variable Adult_mortality stands out as the most influential predictor, with highest F-value (6357.96). The other significant measurement was GDP_per_capita. The least influential variable was Hepatitis_B.

# 